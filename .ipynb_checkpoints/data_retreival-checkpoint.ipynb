{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c392a233-dc32-4a2f-b7d5-14e6f1737ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q snscrape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e2eac5f9-bdf9-4d36-8d72-cb34cf8f8a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "from os import listdir\n",
    "from datetime import date, datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b39a0f11-e4c5-4ed9-921b-abe952abf5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_range(start, end):\n",
    "    delta = end - start  # as timedelta\n",
    "    days = [start + timedelta(days=i) for i in range(delta.days + 1)]\n",
    "    return_days = [day.date() for day in days]\n",
    "    return return_days\n",
    "\n",
    "start_date = datetime(2022, 3, 12)\n",
    "end_date = datetime(2022, 4, 24)\n",
    "    \n",
    "date_range_for_data = date_range(start_date, end_date)\n",
    "\n",
    "\n",
    "def create_tuples(date_range_list): \n",
    "    return_list = []\n",
    "    \n",
    "    # example [(2021-10-31, 2021-11-1), (2021-11-1, 2021-11-2)]\n",
    "    for i in range(len(date_range_list)): \n",
    "        if not(date_range_list[i] == date_range_list[len(date_range_list)-1]):\n",
    "            return_list.append((date_range_list[i], date_range_list[i+1]))\n",
    "\n",
    "    return return_list\n",
    "\n",
    "date_range_tuple = create_tuples(date_range_for_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "37ca24eb-40e4-4d0c-9300-33cf2dc8da6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get tweets function with \n",
    "# inputs (max_results, search_term, from_date, end_date)\n",
    "# For us the from and end date will be the same \n",
    "# it will output a csv in the current directory with date as the start of the file\n",
    "# and the search term (query at the start as well) \n",
    "def get_tweets(tweet_count, text_query, since_date, until_date):\n",
    "    # Using OS library to call CLI commands in Python\n",
    "    os.system('snscrape --jsonl --max-results {} --since {} twitter-search \"{} until:{}\"> text-query-tweets.json'.format( tweet_count, since_date, text_query, until_date))\n",
    "\n",
    "    # Reads the json generated from the CLI command above and creates a pandas dataframe\n",
    "    tweets_df = pd.read_json('text-query-tweets.json', lines=True)\n",
    "    tweets_df.to_csv(f'{since_date}_{text_query}_tweets.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad52865-6dd6-4f5f-9b7b-00a8083fce42",
   "metadata": {},
   "source": [
    "# Do not run this anymore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8392469-cbef-45d2-b566-35ba902f64e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_count = 1000\n",
    "text_query = \"russia ukraine oil\"\n",
    "\n",
    "for date in date_range_tuple:\n",
    "    get_tweets(tweet_count, text_query, date[0], date[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4788b5f3-7471-44e8-9816-978d7e5c2bb6",
   "metadata": {},
   "source": [
    "# Data Preprocessing \n",
    "\n",
    "#### Run this before you proceed with cleaning up and filtering the data \n",
    "\n",
    "#### final_dict - Is this dictionary that contains all the data according to dates as the key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7cabc872-c311-49b8-9a45-cf56c5ef571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = os.getcwd()\n",
    "\n",
    "path_tweets = f'{current_path}/russia_ukraine_tweet/'\n",
    "\n",
    "files = listdir(path_tweets)\n",
    "\n",
    "#read files which end with csv \n",
    "# put them in a list \n",
    "#Input: all files in the directory list of files \n",
    "#Output: filter only the files \n",
    "def filter_csv(files):\n",
    "    \n",
    "    return_list = []\n",
    "    \n",
    "    for f in files: \n",
    "        if f.endswith('csv'):\n",
    "            return_list.append(f)\n",
    "    \n",
    "    return return_list \n",
    "\n",
    "# Tested - Works well\n",
    "files_list = filter_csv(files)\n",
    "            \n",
    "    \n",
    "# write another function which makes a dictionary from a list of csv files \n",
    "# Prerequisite for the dictionary - filenames need to begin with dates \n",
    "# Key: Date Value: CSV \n",
    "# Input list of csv files\n",
    "# Output : Dictionary - date and its constituent df \n",
    "def create_data_dictionary(files_list): \n",
    "    return_dict = {}\n",
    "    files_with_no_data = [] \n",
    "    current_path = os.getcwd()\n",
    "    data_path = f'{current_path}/russia_ukraine_tweet'\n",
    "    for f in files_list:\n",
    "        try:\n",
    "            value = pd.read_csv(f'{data_path}/{f}')\n",
    "            key = f[0:10]\n",
    "            return_dict[key] = value\n",
    "        except:\n",
    "            files_with_no_data.append(f)\n",
    "            continue \n",
    "            \n",
    "    # to check if there are any files which are empty \n",
    "    # there is another way to filter and add it in this function itself but I have broken down \n",
    "    # for easier understanding. \n",
    "    return ((return_dict, files_with_no_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "80cd9a02-337c-458e-a452-9fbd317bb193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166\n"
     ]
    }
   ],
   "source": [
    "final_dict, files_with_no_data = create_data_dictionary(files_list)\n",
    "\n",
    "# without days with no data \n",
    "final_days_of_data = len(final_dict.keys())\n",
    "\n",
    "# input : dictionary , list of files \n",
    "# out : dictionary updated with file names but value is a string - 'no data'\n",
    "def insert_null_val(dict_, files): \n",
    "    for i in files: \n",
    "        dict_[i[0:10]] = 'no value'\n",
    "    \n",
    "    return dict_\n",
    "\n",
    "#with days with no data \n",
    "final_dict = insert_null_val(final_dict, files_with_no_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c404c066-facc-49e7-99d1-0c5f9ac75efa",
   "metadata": {},
   "source": [
    "## Cleaning up each dataframe individually "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1d6ec1c2-983e-46dd-b7da-8eb7cd795a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: \n",
    "# Take a sample \n",
    "# Filter the data \n",
    "# Create functions and test on sample df shown below\n",
    "# source = [twitter for android, twitter for ios, twitter web app, news sources] \n",
    "# language = en (english tweets only)\n",
    "# clean up tweets \n",
    "\n",
    "\n",
    "\n",
    "sample_df = final_dict['2022-03-14']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
